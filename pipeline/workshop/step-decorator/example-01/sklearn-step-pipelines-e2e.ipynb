{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set  path  to config file\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we instantiate a SageMaker Session for our Notebook and retrieve metadata such as the Execution Role and Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in environment variables.\n",
      "INFO:botocore.credentials:Found credentials in environment variables.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.workflow.function_step import step\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "# role을 가져오지 못할 경우, requiremenets.txt에 등록된 Role의 principal을 확인할 것. 변경요망\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter definition\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "instance_type = ParameterString(name=\"TrainInstanceType\", default_value=\"ml.m5.2xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step one\n",
    "@step(\n",
    "  name=\"preprocess\",\n",
    "  instance_type=instance_type,\n",
    "  keep_alive_period_in_seconds=300\n",
    ")\n",
    "def create_data() -> tuple:\n",
    "  import numpy as np\n",
    "  np.random.seed(0)\n",
    "  X = np.random.rand(100, 1)\n",
    "  y = 2*X + 1 + 0.1*np.random.randn(100,1)\n",
    "  data = (X, y)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step two\n",
    "@step(\n",
    "  name=\"training\",\n",
    "  instance_type=instance_type,\n",
    "  keep_alive_period_in_seconds=300\n",
    ")\n",
    "def train_model(data: tuple):\n",
    "  import joblib\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  import boto3\n",
    "\n",
    "  # use boto3 to work with S3\n",
    "  s3 = boto3.client(\"s3\")\n",
    "\n",
    "  # unique bucket name\n",
    "  bucket_name = \"sagemaker-pipelie-step-richard-0304\"\n",
    "  # 생성후 uncomment\n",
    "  # s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={\n",
    "  #                     'LocationConstraint': 'ap-northeast-2'\n",
    "  #                 })\n",
    "\n",
    "  # unpack data\n",
    "  X = data[0]\n",
    "  y = data[1]\n",
    "  # Split the data into training and testing sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  # Create a Linear Regression Model\n",
    "  model = LinearRegression()\n",
    "\n",
    "  # Train the model on the training data\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Serialize trained model for inference\n",
    "  model_filename = \"model.joblib\"\n",
    "  joblib.dump(model, model_filename)\n",
    "\n",
    "  # Upload model artifacts to s3\n",
    "  s3_file_name = \"model-artifacts/model.joblib\" # key to store model artifacts\n",
    "\n",
    "  # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/upload_file.html\n",
    "  # S3.Client.upload_file(Filename, Bucket, Key, ExtraArgs=None, Callback=None, Config=None)\n",
    "  s3.upload_file(model_filename, bucket_name, s3_file_name)\n",
    "  artifacts = (model_filename, bucket_name, s3_file_name, X_test, y_test)\n",
    "  return artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step three\n",
    "@step(\n",
    "  name=\"inference_evaluation\",\n",
    "  instance_type=instance_type,\n",
    "  keep_alive_period_in_seconds=600\n",
    ")\n",
    "def model_inference(artifacts: tuple) ->float:\n",
    "  import joblib\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  import numpy as np\n",
    "  import boto3\n",
    "\n",
    "  s3 = boto3.client(\"s3\")\n",
    "\n",
    "  # load up arifacts from previous step\n",
    "  model_filename = artifacts[0]\n",
    "  bucket_name = artifacts[1]\n",
    "  s3_file_name = artifacts[2]\n",
    "  X_test = artifacts[3]\n",
    "  y_test = artifacts[4]\n",
    "\n",
    "  # download model.joblib\n",
    "  # S3.Client.download_file(Bucket, Key, Filename, ExtraArgs=None, Callback=None, Config=None)\n",
    "  s3.download_file(bucket_name, s3_file_name, model_filename)\n",
    "\n",
    "  # model loading + inference\n",
    "  serialized_model = joblib.load(model_filename)\n",
    "  preds = serialized_model.predict(X_test)\n",
    "\n",
    "  # evaluation\n",
    "  mse = mean_squared_error(y_test, preds)\n",
    "  rmse = float(np.sqrt(mse))\n",
    "\n",
    "  return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Orchestration and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in environment variables.\n"
     ]
    }
   ],
   "source": [
    "# stitch together pipeline\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "data = create_data()\n",
    "artifacts = train_model(data)\n",
    "rmse = model_inference(artifacts)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "  name=\"sklearn-pipeline\",\n",
    "  parameters=[\n",
    "    instance_type\n",
    "  ],\n",
    "  steps=[\n",
    "    rmse,\n",
    "  ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.ImageUri\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.RoleArn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 13:57:16,209 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/inference_evaluation/2024-03-06-13-57-13-264/function\n",
      "2024-03-06 13:57:16,327 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/inference_evaluation/2024-03-06-13-57-13-264/arguments\n",
      "2024-03-06 13:57:16,711 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpzqi7vwfy/requirements.txt'\n",
      "2024-03-06 13:57:16,780 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/inference_evaluation/2024-03-06-13-57-13-264/pre_exec_script_and_dependencies'\n",
      "2024-03-06 13:57:16,786 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmp_5a4jwfp/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2024-03-06 13:57:16,794 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmp_5a4jwfp/workspace.zip'\n",
      "2024-03-06 13:57:16,867 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/sm_rf_user_ws/2024-03-06-13-57-13-264/workspace.zip'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.ImageUri\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.RoleArn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 13:57:19,460 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/training/2024-03-06-13-57-13-264/function\n",
      "2024-03-06 13:57:19,578 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/training/2024-03-06-13-57-13-264/arguments\n",
      "2024-03-06 13:57:19,718 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmp6n7hn6hn/requirements.txt'\n",
      "2024-03-06 13:57:19,778 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/training/2024-03-06-13-57-13-264/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.ImageUri\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.Dependencies\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.IncludeLocalWorkDir\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.CustomFileFilter.IgnoreNamePatterns\n",
      "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.RemoteFunction.RoleArn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 13:57:22,251 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/preprocess/2024-03-06-13-57-13-264/function\n",
      "2024-03-06 13:57:22,377 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/preprocess/2024-03-06-13-57-13-264/arguments\n",
      "2024-03-06 13:57:22,488 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpp6hgfocs/requirements.txt'\n",
      "2024-03-06 13:57:22,547 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/preprocess/2024-03-06-13-57-13-264/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2024-03-06 13:57:23,144 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/inference_evaluation/2024-03-06-13-57-23-144/function\n",
      "2024-03-06 13:57:23,267 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/inference_evaluation/2024-03-06-13-57-23-144/arguments\n",
      "2024-03-06 13:57:23,622 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmp8xztze5b/requirements.txt'\n",
      "2024-03-06 13:57:23,689 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/inference_evaluation/2024-03-06-13-57-23-144/pre_exec_script_and_dependencies'\n",
      "2024-03-06 13:57:23,692 sagemaker.remote_function INFO     Copied user workspace to '/tmp/tmpj06of4n4/temp_workspace/sagemaker_remote_function_workspace'\n",
      "2024-03-06 13:57:23,695 sagemaker.remote_function INFO     Successfully created workdir archive at '/tmp/tmpj06of4n4/workspace.zip'\n",
      "2024-03-06 13:57:23,758 sagemaker.remote_function INFO     Successfully uploaded workdir to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/sm_rf_user_ws/2024-03-06-13-57-23-144/workspace.zip'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2024-03-06 13:57:23,762 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/training/2024-03-06-13-57-23-144/function\n",
      "2024-03-06 13:57:23,888 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/training/2024-03-06-13-57-23-144/arguments\n",
      "2024-03-06 13:57:24,033 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpjkrwm5_x/requirements.txt'\n",
      "2024-03-06 13:57:24,098 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/training/2024-03-06-13-57-23-144/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2024-03-06 13:57:24,102 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/preprocess/2024-03-06-13-57-23-144/function\n",
      "2024-03-06 13:57:24,228 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/preprocess/2024-03-06-13-57-23-144/arguments\n",
      "2024-03-06 13:57:24,350 sagemaker.remote_function INFO     Copied dependencies file at './requirements.txt' to '/tmp/tmpky1majyn/requirements.txt'\n",
      "2024-03-06 13:57:24,419 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-ap-northeast-2-532805286864/sklearn-pipeline/preprocess/2024-03-06-13-57-23-144/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:ap-northeast-2:532805286864:pipeline/sklearn-pipeline',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:ap-northeast-2:532805286864:pipeline/sklearn-pipeline/execution/dtv69dh95025',\n",
       " 'PipelineExecutionDisplayName': 'execution-1709733443796',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2024, 3, 6, 22, 57, 23, 732000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2024, 3, 6, 22, 57, 23, 732000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {},\n",
       " 'LastModifiedBy': {},\n",
       " 'ResponseMetadata': {'RequestId': 'd2a1cf01-0256-420e-a287-ef1bb1484538',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd2a1cf01-0256-420e-a287-ef1bb1484538',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '407',\n",
       "   'date': 'Wed, 06 Mar 2024 13:57:23 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()\n",
    "execution.describe()\n",
    "# execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'inference_evaluation',\n",
       "  'StepDisplayName': '__main__.model_inference',\n",
       "  'StartTime': datetime.datetime(2024, 3, 6, 22, 58, 38, 376000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Executing',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:ap-northeast-2:532805286864:training-job/pipelines-dtv69dh95025-inference-evaluation-fQw9kiHmQ1'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'training',\n",
       "  'StepDisplayName': '__main__.train_model',\n",
       "  'StartTime': datetime.datetime(2024, 3, 6, 22, 58, 1, 194000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 3, 6, 22, 58, 37, 841000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:ap-northeast-2:532805286864:training-job/pipelines-dtv69dh95025-training-tCdqLAkeI1'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'preprocess',\n",
       "  'StartTime': datetime.datetime(2024, 3, 6, 22, 57, 24, 496000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 3, 6, 22, 58, 0, 572000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:ap-northeast-2:532805286864:training-job/pipelines-dtv69dh95025-preprocess-JkqSMWgqsA'}},\n",
       "  'AttemptCount': 1}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
